{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1561ed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for products, brands and more: Mobile 5G above 20k\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "from bs4 import BeautifulSoup  # For web scraping\n",
    "import pandas as pd            # For data manipulation\n",
    "import requests                # For sending HTTP requests\n",
    "\n",
    "# Create empty lists to store the data for this page\n",
    "Product_name, Price, Rating, Total_Rating,Product_link = list(), list(), list(), list(), list()\n",
    "\n",
    "# The outputfile after extraction\n",
    "output_file = 'flipkart_details2'\n",
    "\n",
    "# Get user input for product search\n",
    "user_input = input(\"Search for products, brands and more: \")\n",
    "product = user_input.replace(\" \",\"%20\")\n",
    "\n",
    "# URL used to get the information\n",
    "base_url = f\"https://www.flipkart.com/search?q={product}&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"\n",
    "\n",
    "# Counter for page numbers\n",
    "n = 0\n",
    "\n",
    "# Function to scrape page data and save it to a CSV file\n",
    "def scrape_page(url):\n",
    "    global n\n",
    "    # Send a GET request to the URL and get the response\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Create a BeautifulSoup object from the response text using the html.parser\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Increment page counter\n",
    "    n += 1\n",
    "    \n",
    "    # Extract data from the page using BeautifulSoup selectors or regular expressions\n",
    "    for flipkart in soup.find_all('div', class_='_1AtVbE col-12-12'):\n",
    "        # Extract product name\n",
    "        product_name = flipkart.find('div',class_ = '_4rR01T')\n",
    "        if product_name is not None:        \n",
    "            Product_name.append(product_name.text)\n",
    "        else:\n",
    "            Product_name.append(\"N/A\")\n",
    "\n",
    "        # Extract product price\n",
    "        price = flipkart.find('div', class_='_30jeq3 _1_WHN1')\n",
    "        if price is not None:        \n",
    "            Price.append(price.text)\n",
    "        else:\n",
    "            Price.append(\"N/A\")\n",
    "\n",
    "        # Extract product rating\n",
    "        rating = flipkart.find('div', class_='_3LWZlK')  \n",
    "        if rating is not None:        \n",
    "            Rating.append(rating.text)\n",
    "        else:\n",
    "            Rating.append(\"N/A\")\n",
    "        \n",
    "        # Extract total number of ratings for the product\n",
    "        t_rating = flipkart.find('span', class_='_2_R_DZ')  \n",
    "        if t_rating is not None:\n",
    "            t_clean=((t_rating.text).split(\" \"))[0]\n",
    "            Total_Rating.append(t_clean)\n",
    "        else:\n",
    "            Total_Rating.append(\"N/A\")\n",
    "        \n",
    "        # Extract product link\n",
    "        try:\n",
    "            link1 = flipkart.find('a', class_='_1fQZEK')['href']\n",
    "            link = link1.split(\"?\")[0]\n",
    "            pro_link = \"https://www.flipkart.com\" + link\n",
    "            Product_link.append(pro_link)\n",
    "        except:\n",
    "            Product_link.append('N/A')\n",
    "    \n",
    "    # Create a Pandas DataFrame with the lists and append it to the output file\n",
    "    df = pd.DataFrame({'Product Name': Product_name, 'Price': Price, 'Rating': Rating,\"Total Ratings\":Total_Rating,\"Product Link\":Product_link})\n",
    "    df.to_csv(output_file+'.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    # Return the number of pages in the particular website\n",
    "    return n\n",
    "\n",
    "# Define the total number of pages to scrape\n",
    "\"\"\"response = requests.get(\"https://www.flipkart.com/search?q=laptop&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1\")\n",
    "soup2 = BeautifulSoup(response.text, 'html.parser')\n",
    "num_pages = soup2.find('div', class_=\"_2MImiq\")\n",
    "max_pages=int((num_pages.span.text).split(' ')[3])\"\"\"\n",
    "max_pages=3\n",
    "\n",
    "# Scrape each page in the range of page numbers\n",
    "for page_num in range(1, max_pages + 1):\n",
    "    url = base_url + str(page_num)\n",
    "    # Save the data to a\n",
    "    print(scrape_page(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af757540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total Ratings</th>\n",
       "      <th>Product Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>OPPO K10 5G (Midnight Black, 128 GB)</td>\n",
       "      <td>₹17,499</td>\n",
       "      <td>4.4</td>\n",
       "      <td>67708</td>\n",
       "      <td><a href=\"https://www.flipkart.com/oppo-k10-5g-midnight-black-128-gb/p/itm28cf887931942\" target=\"_blank\">https://www.flipkart.com/oppo-k10-5g-midnight-black-128-gb/p/itm28cf887931942</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Xiaomi 11i 5G (Stealth Black, 128 GB)</td>\n",
       "      <td>₹24,999</td>\n",
       "      <td>4.2</td>\n",
       "      <td>38160</td>\n",
       "      <td><a href=\"https://www.flipkart.com/xiaomi-11i-5g-stealth-black-128-gb/p/itm8f69666fd662e\" target=\"_blank\">https://www.flipkart.com/xiaomi-11i-5g-stealth-black-128-gb/p/itm8f69666fd662e</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>realme 9 Pro+ 5G (Midnight Black, 256 GB)</td>\n",
       "      <td>₹24,999</td>\n",
       "      <td>4.4</td>\n",
       "      <td>30972</td>\n",
       "      <td><a href=\"https://www.flipkart.com/realme-9-pro-5g-midnight-black-256-gb/p/itm15e7a06fe9352\" target=\"_blank\">https://www.flipkart.com/realme-9-pro-5g-midnight-black-256-gb/p/itm15e7a06fe9352</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>realme 9 Pro+ 5G (Midnight Black, 128 GB)</td>\n",
       "      <td>₹22,999</td>\n",
       "      <td>4.4</td>\n",
       "      <td>30972</td>\n",
       "      <td><a href=\"https://www.flipkart.com/realme-9-pro-5g-midnight-black-128-gb/p/itm15e7a06fe9352\" target=\"_blank\">https://www.flipkart.com/realme-9-pro-5g-midnight-black-128-gb/p/itm15e7a06fe9352</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>realme 9 Pro+ 5G (Sunrise Blue, 256 GB)</td>\n",
       "      <td>₹24,999</td>\n",
       "      <td>4.4</td>\n",
       "      <td>30972</td>\n",
       "      <td><a href=\"https://www.flipkart.com/realme-9-pro-5g-sunrise-blue-256-gb/p/itm15e7a06fe9352\" target=\"_blank\">https://www.flipkart.com/realme-9-pro-5g-sunrise-blue-256-gb/p/itm15e7a06fe9352</a></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from IPython.display import HTML  # import the HTML module from the IPython.display library for displaying dataframes in Jupyter notebooks as HTML\n",
    "\n",
    "# Read the CSV file\n",
    "file = output_file+\".csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Clean the data\n",
    "df = df.dropna(subset=['Product Name','Price','Product Link'])\n",
    "df = df.drop_duplicates()\n",
    "df = df[df['Product Name'] != 'Product Name']\n",
    "df.to_csv('flipkart_link.csv', index=False)\n",
    "\n",
    "# Read the cleaned CSV file\n",
    "df_new = pd.read_csv('flipkart_link.csv')\n",
    "\n",
    "# Convert 'Total Ratings' column to integers\n",
    "df_new['Total Ratings'] = df_new['Total Ratings'].str.replace(',', '').fillna('0').astype(int)\n",
    "\n",
    "# Create a 'Highly_Ratings' column based on the 'Total_Ratings' column\n",
    "df_new['Highly Ratings'] = df_new['Total Ratings'] > 1000\n",
    "\n",
    "# Filter the DataFrame to only show highly rated items\n",
    "highly_rated = df_new[df_new['Highly Ratings']]\n",
    "\n",
    "# Sort the 'Total Ratings' column in descending order\n",
    "sorted_df = highly_rated.sort_values('Total Ratings', ascending=False)\n",
    "\n",
    "# Format the 'Product Link' column as clickable links\n",
    "sorted_df.loc[:, 'Product Link'] = sorted_df['Product Link'].apply(lambda x: '<a href=\"{}\" target=\"_blank\">{}</a>'.format(x, x))\n",
    "\n",
    "# Display the top 5 rows of the sorted dataframe\n",
    "top_5 = sorted_df.head(5)\n",
    "#display(HTML(top_5.to_html(escape=False)))\n",
    "## Display only the first four columns of the top 5 rows of the sorted dataframe\n",
    "display(HTML(top_5.iloc[:, :5].to_html(escape=False)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
